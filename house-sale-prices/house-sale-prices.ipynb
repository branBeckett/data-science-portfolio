{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Sale Prices\n",
    "\n",
    "In this project, we'll explore ways to build and improve a linear regression model by working with housing data for the city of Ames, Iowa from 2006 to 2010. Information on the dataset can be found [here](https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627), and the columns info can be found [here](https://s3.amazonaws.com/dq-content/307/data_description.txt).\n",
    "\n",
    "## Building the Pipeline\n",
    "\n",
    "We'll start by importing our libraries, reading in our data, and then setting up a pipeline of functions that will help us quickly iterate over different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AmesHousing.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  57088.25\n"
     ]
    }
   ],
   "source": [
    "# Returns training Data Frame\n",
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    features = numeric_train.columns.drop('SalePrice')\n",
    "    \n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test['SalePrice'], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "print(\"RMSE: \", round(rmse, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Next, we'll begin removing features that have too many missing values, look for potential categorical features, and transform the text and numerical columns.\n",
    "\n",
    "We'll start by updating our `transform_features()` function so that any column with more than XX% missing values is dropped. We'll also remove columns that leak information about the sale. We'll need to read the data documentation to get a better idea of what transformations are necessary and for which columns.\n",
    "\n",
    "1) For **all columns**, drop any with 5% or more missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create series with missing values data\n",
    "val_missing = df.isnull().sum()\n",
    "\n",
    "# Filter the columns containing > 5% missing values\n",
    "missing_val_cols = val_missing[(val_missing > len(df)/20)].sort_values()\n",
    "\n",
    "# Drop missing value columns\n",
    "df = df.drop(missing_val_cols.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) For **text columns**, drop any with 1 or more missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create series with missing text values data\n",
    "text_missing = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "# Filter the text columns containing any missing values\n",
    "missing_text_cols = text_missing[text_missing > 0]\n",
    "\n",
    "# Drop missing value columns\n",
    "df = df.drop(missing_text_cols.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) For **numerical columns**, fill in with the most common value in that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1       1\n",
       "BsmtFin SF 2       1\n",
       "Bsmt Unf SF        1\n",
       "Total Bsmt SF      1\n",
       "Garage Cars        1\n",
       "Garage Area        1\n",
       "Bsmt Full Bath     2\n",
       "Bsmt Half Bath     2\n",
       "Mas Vnr Area      23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute missing value counts\n",
    "num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "fixable_num_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "fixable_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BsmtFin SF 1': 0.0,\n",
       " 'BsmtFin SF 2': 0.0,\n",
       " 'Bsmt Unf SF': 0.0,\n",
       " 'Total Bsmt SF': 0.0,\n",
       " 'Garage Cars': 2.0,\n",
       " 'Garage Area': 0.0,\n",
       " 'Bsmt Full Bath': 0.0,\n",
       " 'Bsmt Half Bath': 0.0,\n",
       " 'Mas Vnr Area': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the most common value for each of the columns in `fixable_num_cols`\n",
    "replacement_vals = df[fixable_num_cols.index].mode().to_dict(orient='records')[0]\n",
    "replacement_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace missing values\n",
    "df = df.fillna(replacement_vals)\n",
    "\n",
    "# Verify no missing values left\n",
    "df.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at what new features we can create to better capture some of the information in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_sold = df['Yr Sold'] - df['Year Built']\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_remodel = df['Yr Sold'] - df['Year Remod/Add']\n",
    "years_remodel[years_remodel < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new columns\n",
    "df['Years Before Sale'] = years_sold\n",
    "df['Years Since Remodel'] = years_remodel\n",
    "\n",
    "# Drop the rows with negative values for both new features\n",
    "df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "# Remove original year columns\n",
    "df = df.drop(['Year Built', 'Year Remod/Add'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll drop the columns that aren't useful in machine learning models and columns that leak data about the final sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not useful\n",
    "df = df.drop(['PID', 'Order'], axis=1)\n",
    "\n",
    "# Drop columns that leak info\n",
    "df = df.drop(['Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update the `transform_features()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  55275.37\n"
     ]
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    \n",
    "    val_missing = df.isnull().sum()\n",
    "    missing_val_cols = val_missing[(val_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(missing_val_cols.index, axis=1)\n",
    "    \n",
    "    text_missing = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    missing_text_cols = text_missing[text_missing > 0]\n",
    "    df = df.drop(missing_text_cols.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_num_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_vals = df[fixable_num_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_vals)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_remodel = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remodel'] = years_remodel\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    \n",
    "    df = df.drop(['Year Built', 'Year Remod/Add', 'PID', 'Order', 'Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'], axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    features = numeric_train.columns.drop('SalePrice')\n",
    "    \n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test['SalePrice'], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "df = pd.read_csv('AmesHousing.tsv', delimiter='\\t')\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "print(\"RMSE: \", round(rmse, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Now that we've cleaned and transformed our data, we can move on to selecting our features for our model.\n",
    "\n",
    "We'll start by looking at how numerical features in our training set correlate with `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Years Before Sale</th>\n",
       "      <th>Years Since Remodel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105000</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>172000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244000</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189900</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MS SubClass  Lot Area  Overall Qual  Overall Cond  Mas Vnr Area  \\\n",
       "0           20     31770             6             5         112.0   \n",
       "1           20     11622             5             6           0.0   \n",
       "2           20     14267             6             6         108.0   \n",
       "3           20     11160             7             5           0.0   \n",
       "4           60     13830             5             5           0.0   \n",
       "\n",
       "   BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF  1st Flr SF  \\\n",
       "0         639.0           0.0        441.0         1080.0        1656   \n",
       "1         468.0         144.0        270.0          882.0         896   \n",
       "2         923.0           0.0        406.0         1329.0        1329   \n",
       "3        1065.0           0.0       1045.0         2110.0        2110   \n",
       "4         791.0           0.0        137.0          928.0         928   \n",
       "\n",
       "   2nd Flr SF  Low Qual Fin SF  Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath  \\\n",
       "0           0                0         1656             1.0             0.0   \n",
       "1           0                0          896             0.0             0.0   \n",
       "2           0                0         1329             0.0             0.0   \n",
       "3           0                0         2110             1.0             0.0   \n",
       "4         701                0         1629             0.0             0.0   \n",
       "\n",
       "   Full Bath  Half Bath  Bedroom AbvGr  Kitchen AbvGr  TotRms AbvGrd  \\\n",
       "0          1          0              3              1              7   \n",
       "1          1          0              2              1              5   \n",
       "2          1          1              3              1              6   \n",
       "3          2          1              3              1              8   \n",
       "4          2          1              3              1              6   \n",
       "\n",
       "   Fireplaces  Garage Cars  Garage Area  Wood Deck SF  Open Porch SF  \\\n",
       "0           2          2.0        528.0           210             62   \n",
       "1           0          1.0        730.0           140              0   \n",
       "2           0          1.0        312.0           393             36   \n",
       "3           2          2.0        522.0             0              0   \n",
       "4           1          2.0        482.0           212             34   \n",
       "\n",
       "   Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area  Misc Val  SalePrice  \\\n",
       "0               0           0             0          0         0     215000   \n",
       "1               0           0           120          0         0     105000   \n",
       "2               0           0             0          0     12500     172000   \n",
       "3               0           0             0          0         0     244000   \n",
       "4               0           0             0          0         0     189900   \n",
       "\n",
       "   Years Before Sale  Years Since Remodel  \n",
       "0                 50                   50  \n",
       "1                 49                   49  \n",
       "2                 52                   52  \n",
       "3                 42                   42  \n",
       "4                 13                   12  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = transform_df.select_dtypes(include=['int', 'float'])\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice              1.000000\n",
       "Overall Qual           0.801206\n",
       "Gr Liv Area            0.717596\n",
       "Garage Cars            0.648361\n",
       "Total Bsmt SF          0.644012\n",
       "Garage Area            0.641425\n",
       "1st Flr SF             0.635185\n",
       "Years Before Sale      0.558979\n",
       "Full Bath              0.546118\n",
       "Years Since Remodel    0.534985\n",
       "Mas Vnr Area           0.506983\n",
       "TotRms AbvGrd          0.498574\n",
       "Fireplaces             0.474831\n",
       "BsmtFin SF 1           0.439284\n",
       "Wood Deck SF           0.328183\n",
       "Open Porch SF          0.316262\n",
       "Half Bath              0.284871\n",
       "Bsmt Full Bath         0.276258\n",
       "2nd Flr SF             0.269601\n",
       "Lot Area               0.267520\n",
       "Bsmt Unf SF            0.182751\n",
       "Bedroom AbvGr          0.143916\n",
       "Enclosed Porch         0.128685\n",
       "Kitchen AbvGr          0.119760\n",
       "Screen Porch           0.112280\n",
       "Overall Cond           0.101540\n",
       "MS SubClass            0.085128\n",
       "Pool Area              0.068438\n",
       "Low Qual Fin SF        0.037629\n",
       "Bsmt Half Bath         0.035875\n",
       "3Ssn Porch             0.032268\n",
       "Misc Val               0.019273\n",
       "BsmtFin SF 2           0.006127\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "corr_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice              1.000000\n",
       "Overall Qual           0.801206\n",
       "Gr Liv Area            0.717596\n",
       "Garage Cars            0.648361\n",
       "Total Bsmt SF          0.644012\n",
       "Garage Area            0.641425\n",
       "1st Flr SF             0.635185\n",
       "Years Before Sale      0.558979\n",
       "Full Bath              0.546118\n",
       "Years Since Remodel    0.534985\n",
       "Mas Vnr Area           0.506983\n",
       "TotRms AbvGrd          0.498574\n",
       "Fireplaces             0.474831\n",
       "BsmtFin SF 1           0.439284\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the columns with a correlation coefficient > 0.4\n",
    "corr_coeffs[corr_coeffs > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with a correlation coefficient < 0.4\n",
    "transform_df = transform_df.drop(corr_coeffs[corr_coeffs < 0.4].index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's decide which categorical columns we should keep. Some columns may be numerical but need to be encoded as categorical instead, and some columns with too many unique values might be best left out, otherwise we'd have to add hundreds of dummy variable columns to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names that are supposed to be categorical\n",
    "nominal_features = ['PID', 'MS SubClass', 'MS Zoning', 'Street', 'Alley', 'Land Contour', 'Lot Config', 'Neighborhood', \n",
    "                    'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl', 'Exterior 1st', \n",
    "                    'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Heating', 'Central Air', 'Garage Type', \n",
    "                    'Misc Feature', 'Sale Type', 'Sale Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at unique values in the categorical columns\n",
    "categorical_cols = []\n",
    "for col in nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        categorical_cols.append(col)\n",
    "        \n",
    "unique_count = transform_df[categorical_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "\n",
    "# Drop categorical columns with more than 10 unique values\n",
    "drop_unique_cols = unique_count[unique_count > 10].index\n",
    "transform_df = transform_df.drop(drop_unique_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select remaining text columns and convert to categorical columns\n",
    "text_cols = transform_df.select_dtypes(include=['object'])\n",
    "\n",
    "for col in text_cols:\n",
    "    transform_df[col] = transform_df[col].astype('category')\n",
    "    \n",
    "# Create dummy columns and add them to the dataframe\n",
    "transform_df = pd.concat([transform_df,\n",
    "                          pd.get_dummies(transform_df.select_dtypes(include=['category']))\n",
    "                         ], axis=1).drop(text_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test\n",
    "\n",
    "Finally, let's update the `select_features()` function. We'll also add in a parameter named k to our `train_and_test()` function that will control the type of cross validations that occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Values:  [25937.807461762204, 38941.9349743024, 27151.223356899758, 24948.372629900896]\n",
      "RMSE:  29244.83\n"
     ]
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    \n",
    "    val_missing = df.isnull().sum()\n",
    "    missing_val_cols = val_missing[(val_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(missing_val_cols.index, axis=1)\n",
    "    \n",
    "    text_missing = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    missing_text_cols = text_missing[text_missing > 0]\n",
    "    df = df.drop(missing_text_cols.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_num_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_vals = df[fixable_num_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_vals)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_remodel = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remodel'] = years_remodel\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    \n",
    "    df = df.drop(['Year Built', 'Year Remod/Add', 'PID', 'Order', 'Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold'], axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_features(df, coeff_threshold=0.4, unique_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=['int', 'float'])\n",
    "    corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "    df = df.drop(corr_coeffs[corr_coeffs < coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = ['PID', 'MS SubClass', 'MS Zoning', 'Street', 'Alley', 'Land Contour', 'Lot Config', 'Neighborhood', \n",
    "                    'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl', 'Exterior 1st', \n",
    "                    'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Heating', 'Central Air', 'Garage Type', \n",
    "                    'Misc Feature', 'Sale Type', 'Sale Condition']\n",
    "    \n",
    "    categorical_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            categorical_cols.append(col)\n",
    "        \n",
    "    unique_count = df[categorical_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_unique_cols = unique_count[unique_count > unique_threshold].index\n",
    "    df = df.drop(drop_unique_cols, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "        \n",
    "    df = pd.concat([df,\n",
    "                    pd.get_dummies(df.select_dtypes(include=['category']))\n",
    "                    ], axis=1).drop(text_cols, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    features = numeric_df.columns.drop('SalePrice')\n",
    "    lr = linear_model.LinearRegression()\n",
    "    \n",
    "    if k == 0:\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train['SalePrice'])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test['SalePrice'], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "    \n",
    "        return rmse\n",
    "    \n",
    "    if k == 1:\n",
    "        # Randomize rows in df\n",
    "        shuffled_df = df.sample(frac=1, )\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train['SalePrice'])\n",
    "        predictions_one = lr.predict(test[features])\n",
    "        mse_one = mean_squared_error(test['SalePrice'], predictions_one)\n",
    "        rmse_one = np.sqrt(mse_one)\n",
    "        \n",
    "        lr.fit(train[features], train['SalePrice'])\n",
    "        predictions_two = lr.predict(test[features])\n",
    "        mse_two = mean_squared_error(test['SalePrice'], predictions_two)\n",
    "        rmse_two = np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "        \n",
    "        print('RMSE 1: ', round(rmse_one, 2))\n",
    "        print('RMSE 2: ', round(rmse_two, 2))\n",
    "        \n",
    "        return avg_rmse\n",
    "    \n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train['SalePrice'])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test['SalePrice'], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        \n",
    "        print('RMSE Values: ', rmse_values)\n",
    "        \n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return avg_rmse\n",
    "\n",
    "df = pd.read_csv('AmesHousing.tsv', delimiter='\\t')\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df, k=4)\n",
    "\n",
    "print('RMSE: ', round(rmse, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    "\n",
    "In this project we went through the process of building a linear regression model to accurately predict house sale prices. If we'd like to continue improving this model, some potential next steps would be to:\n",
    "\n",
    "* Continue the feature engineering process and try the model after with different hyperparameters.\n",
    "* Look at the Kaggle kernels page for this dataset to see what approaches others have taken.\n",
    "* Work on improving our feature selection, and find better ways to handle our categorical columns.\n",
    "\n",
    "The idea for this project comes from the [DATAQUEST](https://app.dataquest.io/) **Linear Regression For Machine Learning** course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
